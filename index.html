<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Su Wang</title>
  
  <meta name="author" content="Jiahao Nie">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="image2/xjtu.png">
</head>

  <body>
  <table width="950" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="70%" valign="middle">
        <p align="center">
          <name>Su Wang &nbsp;&nbsp;&nbsp; 王 粟 &nbsp;&nbsp;&nbsp;&nbsp;
		  </name>
        </p>

		<p style="line-height: 1.6em;">
   
      <!-- supervised by <a href="http://www.jie-chen.com/">Prof. Jie Chen</a>. -->
	  
	  Wang Su is currently a postgraduate student at Xi'an Jiaotong University of <a href="http://www.aiar.xjtu.edu.cn/index.htm">Institute of Artificial Intelligence and Robotics (IAIR)</a>. To be awarded a master's degree in June 2023. He once obtained a bachelor's degree in software engineering from Xi'an Jiaotong University in 2020.
    </p>  
    My current research interest includes: Computer Vision, Artificial Intelligence, Visual Multimodal Fusion, Machine Learning, Point Cloud Perception.


        <p align=center>
          <a href="mailto:suwang747@gmail.com">Email</a> &nbsp/&nbsp
          <a href="image2/Su_Wang_CV.pdf">CV</a> &nbsp/&nbsp


        </p>
      </td>
      <td width="30%">
      <img src="image2/photo3.jpg" width="200">
      </td>

      </tr>
      </table>

<p></p><p></p><p></p><p></p><p></p>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>News</heading>
          <p>
          <li> <strongsmall>[2022/10]</strongsmall> &nbsp;&nbsp;<smalll>Serve as a reviewer for ICRA 2023.</smalll><br/>    
		  <li> <strongsmall>[2022/9.13]</strongsmall> &nbsp;&nbsp;<smalll>1 paper is accepted by ICTAI 2022.</smalll><br/>
          <li> <strongsmall>[2022/9.05]</strongsmall> &nbsp;&nbsp;<smalll>1 paper is accepted by Neurocomputing (2022).</smalll><br/>
            <li> <strongsmall>[2022/7.16]</strongsmall> &nbsp;&nbsp;<smalll>On the Intelligent Visual Computing Group in IAIR (Oral presentation).</smalll><br/>
          </p>
        </td>
      </tr>
</table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Education</heading>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

        <tr>
          <td width="10%">
            <img src='image2/xjtu.png' width="100">
          </td>

          <td width="75%" valign="middle">
          <p style="line-height: 1.4em;">
          <stronghuge> Xi'an Jiaotong University, &nbsp; China</stronghuge><br />
          M.S. in Computer Science &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2020 - Present<br />
          GPA: <strong>3.3</strong>/4.0 <br />
          Core Courses: Machine Learning  &nbsp;&nbsp; Deep Learning <br />
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
          </p>
        </td>
      </tr>

        <tr>
          <td width="10%">
            <img src='image2/xjtu.png' width="100">
          </td>

          <td width="75%" valign="middle">
          <p style="line-height: 1.4em;">
          <stronghuge> Xi'an Jiaotong University, &nbsp; China</stronghuge><br />
          B.ENG. in Computer Science &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2016 - Jun. 2020<br />
		  Core Courses:  Design and Analysis of Algorithms &nbsp;&nbsp;  Operating System
          </p>
        </td>
      </tr>    
	  
      </table>






<p></p><p></p><p></p><p></p><p></p>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research Experience</heading>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="10%">
            <img src='image2/IAIR.png' width="100">
          </a>
          </td>

          <td width="80%" valign="middle">
          <p  style="line-height: 1.3em;">
          <stronghuge>Institute of Artificial Intelligence and Robotics(IAIR), &nbsp; Xi'an Jiaotong University</stronghuge><br />
          <huge><em>M.S. Dissertation Project & Research Associate</em></huge> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2020 - Present <br />
          Advisors: &nbsp;
          <a href="http://gr.xjtu.edu.cn/web/liuyh">Yuehu Liu</a>
          
          <li> Lidar-based 3D Object Detection in Road Scenes. <br/>
          <li> Point Cloud Registration Based on Transformer.<br/>
          <li> Semantic Segmentation of Multimodal. <br/>
          </p>
        </td>
      </tr>
      
  	   <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="10%">
            <img src='image2/MEGVII.png' width="100">
          </a>
          </td>

          <td width="80%" valign="middle">
          <p  style="line-height: 1.3em;">
          <stronghuge>MEGVII </stronghuge><br />
          <huge><em>Research Associate</em></huge> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2022 - Nov. 2022 <br />
          
          <li> Research on 3D lane detection based on 3D road scene. <br/>
          <li> A virtual camera detection method based on BEV is proposed.<br/>
          <li> Results will be submitted to CVPR 2023. <br/>
          </p>
        </td>
      </tr>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="10%">
            <img src='image2/ascend.png' width="100">
            </a>
          </td>

          <td width="80%" valign="middle">
          <p  style="line-height: 1.3em;">
          <stronghuge>Ascend Ecological Development Department, &nbsp; Huawei</stronghuge><br />
          <huge><em>Research  Assistant</em></huge> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Mar. 2022 - Jun. 2022 <br />

          <li> Transplanted the deep learning model to Huawei’s Ascend AI processor for deployment. <br/>
          <li> Completed the compatibility and performance verification of both systems.<br/>
		  <li> Achieved the required accuracy and performance on the Ascend AI processor about several DL models.<br/>
          </p>
        </td>
      </tr>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="10%">
            <img src='image2/boyun.png' width="100">
            </a>
          </td>

          <td width="80%" valign="middle">
          <p  style="line-height: 1.3em;">
          <stronghuge>Boyun Vision (Beijing) Technology</stronghuge><br />
          <huge><em>Research  Assistant</em></huge> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Feb. 2021 - Jun. 2021 <br />
          
          <li> Building a classification detector for photos. <br/>
          <li> Building an anomaly detector for road guardrail photos. <br/>
          <li> Embed the detector into the app.
          </p>
        </td>
      </tr>

      


      
  


<p></p><p></p><p></p><p></p><p></p>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Publication <!--<a href="https://scholar.google.com/citations?user=LGM10RQAAAAJ&hl=en&oi=ao" style="font-size:22px;">[Google Scholar]</a></heading>-->
        </td>
      </tr>
      </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='image2/tadp.png'  width="200">
      </td>
      <td valign="top" width="75%">
	 <strong>TADP: Task-Aware Deformable Prediction for Single-Stage 3D Object Detection</strong><br>
	 <strong>Su Wang</strong>, Yaochen Li, Min Yang, Jiahao Nie, Rui Huang, Yuehu Liu.  &nbsp;(First Student Author)<br>  
        <em>IEEE International Conference on Information Communication and Signal Processing (ICRA 2023), <strong>CCF-B  CORE-B</strong>
          <br>
        <em>Area: Point Cloud Object Detection;&nbsp; Point Cloud Perception; </em> <br>
        <p></p>
		<p>proposes a new point cloud single-stage detector TADP: Task-Aware Deformable Prediction 
		for Single-Stage 3D Object Detection. We propose TFRA module to extract 3D features with multiple scales. 
		MSFA module is adopted to fuse features in the scale-aware method. A plug-and-play task-aware deformation head (TADH)
		which is to reduce the misalignment of features in all tasks.
		</p>
      </td>
    </tr>
   </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='image2/RITNet.png'  width="200">
      </td>
      <td valign="top" width="75%">
	 <strong>RITNet: A Rotation Invariant Transformer based Network for Point Cloud Registration</strong><br>
	 Min Yang, <strong>Su Wang</strong>, Yaochen Li, Shaohan Yang, Hujun Liu.  &nbsp;(Second Student Author)<br>
        <em>Accepted by IEEE International Conference on Tools with Artificial Intelligence (ICTAI 2022) <strong>CCF-C CORE-B</strong>
         <br>
        <em>Area: Point Cloud Registration;&nbsp; Transformer;</em> <br>
        <p></p>
		<p>We believe that enhancing point cloud boundary features can be further enhanced by rotation information. 
		We propose a rotation invariant representation to replace common 3D Cartesian coordinates . 
		Enhanced generalization to arbitrary orientations using a rotation-invariant Transformer for point cloud registration. 
		The insensitivity to data arrangement and quantity in Transformer technology is exploited to capture global structural 
		knowledge within local parts to perceive each point cloud.</p>
      </td>
    </tr>
   </table>
   
   
       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='image2/multi-level.png'  width="200">
      </td>
      <td valign="top" width="75%">
	 <strong>Multi-level Object Detection by Multi-Sensor Perception of Traffic Scenes</strong><br>
	 Sheng Yuan, Qi Zhang, Li Zhu, <strong>Su Wang</strong>, Yujie Zang, Xi Zhao &nbsp;(Second Student Author)<br>
        <em>Accepted by SCI Neurocomputing <strong>JCR Q2</strong>
        <br>
        <em>Area: Point Cloud Object Detection;&nbsp; Multimodal fusion of RGB and point clouds;</em> <br>
        <p></p>
		<p>we propose a novel framework for multi-level object detection by mutli-sensor perception from road scenes. Firstly, an improved 2D object detection method based on RetinaNet is 
		designed by the optimization of the sub-network of ResNet. The coordinate attention mechanism and bidirectional feature fusion mechanism are incorporated. Finally, we 
		propose a 3D object detection method based on an improved PointNet network. The point cloud data are projected into a frustum according to the 2D detection result, then 
		the frustum is segmented according to the linearly increased steps.</p>
      </td>
    </tr>
   </table>
   
   
   
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='image2/reforced_second.png'  width="200">
      </td>
      <td valign="top" width="75%">
	 <strong>Reinforced SECOND: Attentional 3D Object Detection with Residual Sparse Convolution</strong><br>
	 Qiao Li, Wenneng Tang, <strong>Su Wang</strong>, Yaochen Li, Xuehan Hou, Yuehu Liu  &nbsp;(Third Student Author)<br>
        <em>IEEE International Conference on Robotics and Automation (ICRA 2023) <strong>CCF-B  CORE-B</strong>
        <br>
        <em>Area: 3D Object Detection</em> <br>
        <p></p>
		<p>we propose a 3D object detection method using SECOND as the baseline, namely Reinforced SECOND. 
		A robust voxel encoder network is firstly introduced that extracts voxelwise features. At the same time, the stacked triple 
		attention mechanism is developed to enhance crucial features of the voxels. The residual 3D sparse convolution (ResSpConv3D)
		unit is then designed to replace the normal 3D sparse convolution, which improves the feature extraction ability of the sparse 
		convolution layer while maintaining the original information. Furthermore, the proposed attentional feature fusion (AFF) module 
		is incorporated into the region proposal network, which adaptively fuses low-level spatial features and high-level semantic features. </p>
      </td>
    </tr>
   </table>
   

   
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='image2/frustum.png'  width="200">
      </td>
      <td valign="top" width="75%">
	 <strong>Frustum PointNet for 3D Object Detection from Traffic Scenes</strong><br>
	 Liangyu Zuo, Wenneng Tang,<strong>Su Wang</strong>, Yaochen Li, Yuehu Liu, Weili Guan &nbsp;(Third Student Author)<br>
        <em>ACM Transactions on Multimedia Computing Communications and Applications
        <br>
        <em>Area: Multimodal Fusion;&nbsp; 3D Object Detection, </em> <br>
        <p></p>
		<p>We propose a novel 3D ConvNet with a deep architecture to realize action recognition in IR videos. 
      Besides, a residual fully connected module is introduced after the ConvNet backbone to improve the performance. 
      Furthermore, we employe a transfer learning strategy, i.e., the proposed method is pretrained on a large-scale visible spectrum dataset 
      and then ﬁnetuned with false-color version of IR images to generalize well in the action recognition task.</p>
      </td>
    </tr>
   </table>

<p></p><p></p><p></p><p></p><p></p>
   <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td width="100%" valign="middle">
        <heading>Other Project</heading>
      </td>
    </tr>
    </table>
 


	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="15%">
          <img src='image2/BEVlane.png' width="200">
          </a>
        </td>
 
        <td width="80%" valign="middle">
        <p>
        <stronghuge>Deployment-Oriented Monocular 3D Lane Detector, &nbsp; <br />
          Research Assistant, &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2022 - Nov. 2022 <br />
        <li> Virtual Camera eliminates the difference in poses of cameras mounted on different vehicles. <br/>

        </p>
      </td>
    </tr>
    
    
	
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="15%">
          <img src='image2/benke2.png' width="200">
          </a>
        </td>
 
        <td width="80%" valign="middle">
        <p>
        <stronghuge>Object Detection Algorithm, &nbsp; <br />
          Bachelor Diploma thesis (Design), &nbsp; Xi'an Jiaotong University</stronghuge><br />
        <huge><em>Grade: A</em></huge> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Feb. 2020 - Jun. 2020 <br />
        <li> We improve the F-PointNet algorithm to detect 3D object. <br/>
		
        </p>
      </td>
    </tr>
	
 
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="15%">
          <img src='image2/benke.png' width="200">
          </a>
        </td>
 
        <td width="80%" valign="middle">
        <p>
        <stronghuge>Road Scene Simulation System, &nbsp; <br />
          Bachelor Diploma thesis (Design), &nbsp; Xi'an Jiaotong University</stronghuge><br />
        <huge><em>Grade: A</em></huge> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Feb. 2020 - Jun. 2020 <br />
        <li> Construct a model of the crossroad using Unity. <br/>
        <li> Construct simulation algorithm for component car turning, avoiding and going straight. <br/>
        </p>
      </td>
    </tr>
	

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="15%">
          <img src='image2/suiyuan.png' width="200">
          </a>
        </td>
 
        <td width="80%" valign="middle">
        <p>
        <stronghuge>Enflame Technology Company&nbsp;</stronghuge><br />
        <huge><em>Research  Assistant</em></huge> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Jul. 2019 - Sep. 2019 <br />
        <li> Transplanted the deep learning model to Enflame's TDU.<br/>
        <li> Completed the compatibility and performance verification of both systems.<br/>
        <li> Achieved the required accuracy and performance on the Enflame's TDU.<br/>
        </p>
      </td>
    </tr>




    <p></p><p></p><p></p><p></p><p></p>
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Activity</heading>
              <div style="line-height:25px">
              <p>
          <li> <stronghuge>Monitor, Xi'an Jiaotong University, XJTU</stronghuge>&nbsp; 2020 - 2023<br/>
		  <li> <stronghuge>Academic assistant, SOFT300327 Data Structure, Xi'an Jiaotong University, XJTU</stronghuge>&nbsp; 2021 - 2022<br/>
		  <li> <stronghuge>Academic assistant, SOFT610111 Principles and Technology of Artificial Intelligence, , Xi'an Jiaotong University, XJTU</stronghuge> &nbsp; 2021 - 2022<br/>
          <li> <stronghuge>First Class University Scholarship, Xi'an Jiaotong University, XJTU</stronghuge>&nbsp; 2021 <br/>
          <li> <stronghuge>Outstanding Graduate Student Cadres, Xi'an Jiaotong University, XJTU</stronghuge>&nbsp; 2021 <br/>
          <li> <stronghuge>Student Union Star, Xi'an Jiaotong University, XJTU</stronghuge>&nbsp; 2021 <br/>
          <li> <stronghuge>Vice Chairman, Student Union of Suzhou Research Institute, Xi'an Jiaotong University, XJTU</stronghuge>&nbsp; 2020 - 2021<br/>
          <br/>
		  <li> <stronghuge>Vice Chairman, Community Management Committee, Xi'an Jiaotong University, XJTU</stronghuge>&nbsp; 2018 - 2019<br/>
          <li> <stronghuge>Outstanding student leaders,  Xi'an Jiaotong University, XJTU</stronghuge>&nbsp; 2018 <br/>
          <li> <stronghuge>Excellent Minister, Community Management Committee, Xi'an Jiaotong University, XJTU</stronghuge>&nbsp2017 - 2018<br/>
          <li> <stronghuge>School Student Representatives, Xi'an Jiaotong University, XJTU</stronghuge>&nbsp2017 - 2018<br/>
          <li> <stronghuge>Volunteer, China Science and Technology Education Development Seminar ,Xi'an Jiaotong University, XJTU</stronghuge>&nbsp2017<br/>
		      </p>
              </div>
            </td>
          </tr>
    </table>







<p></p><p></p><p></p><p></p><p></p>
<table style="width:25%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
  <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=OnTintSFonO7-K8tIUMxW0S9HCuQMwuQfZ9IXD_tToI&cl=ffffff&w=a"></script>
</tbody>
</tab