<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Su Wang</title>
  
  <meta name="author" content="Jiahao Nie">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="image2/xjtu.png">
</head>

  <body>
  <table width="950" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="70%" valign="middle">
        <p align="center">
          <name>Su Wang &nbsp;&nbsp;&nbsp; 王 粟  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
		  </name>
        </p>

		<p style="line-height: 1.6em;">
   
      <!-- supervised by <a href="http://www.jie-chen.com/">Prof. Jie Chen</a>. -->
	  
	  Wang Su is currently a postgraduate student at Xi'an Jiaotong University of <a href="http://www.aiar.xjtu.edu.cn/index.htm">Institute of Artificial Intelligence and Robotics (IAIR)</a>. To be awarded a master's degree in June 2023. He once obtained a bachelor's degree in software engineering from Xi'an Jiaotong University in 2020.
    </p>  
    His research interest includes Computer Vision, Artificial Intelligence, Machine Learning.


        <p align=center>
          <a href="mailto:suwang747@gmail.com">Email</a> &nbsp/&nbsp
          <a href="image2/suwangCV.pdf">CV</a> &nbsp/&nbsp


        </p>
      </td>
      <td width="30%">
      <img src="image2/photo.jpg" width="200">
      </td>

      </tr>
      </table>


<p></p><p></p><p></p><p></p><p></p>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>News</heading>
          <p>
		  <li> <strongsmall>[2021/10]</strongsmall> &nbsp;&nbsp;<smalll>1 paper is accepted by IEEE ICICSP 2021.</smalll><br/>
          
          </p>
        </td>
      </tr>
</table>


      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Education</heading>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

        <tr>
          <td width="10%">
            <img src='image2/xjtu.png' width="100">
          </td>

          <td width="75%" valign="middle">
          <p style="line-height: 1.4em;">
          <stronghuge> Xi'an Jiaotong University, &nbsp; China</stronghuge><br />
          M.S. in software engineering &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2020 - Present<br />
          GPA: <strong>3.56</strong>/4.0 <br />
          Core Courses: Machine Learning  &nbsp;&nbsp; Deep Learning <br />
          &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
          </p>
        </td>
      </tr>

        <tr>
          <td width="10%">
            <img src='image2/xjtu.png' width="100">
          </td>

          <td width="75%" valign="middle">
          <p style="line-height: 1.4em;">
          <stronghuge> Xi'an Jiaotong University, &nbsp; China</stronghuge><br />
          B.ENG. in software engineering &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2016 - Jun. 2020<br />
          GPA: <strong>3.40</strong>/4.0 <br />
		  Core Courses:  Design and Analysis of Algorithms &nbsp;&nbsp;  Operating System
          </p>
        </td>
      </tr>    
	  
      </table>






<p></p><p></p><p></p><p></p><p></p>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research Experience</heading>
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="10%">
            <img src='image2/IAIR.png' width="100">
          </a>
          </td>

          <td width="80%" valign="middle">
          <p  style="line-height: 1.3em;">
          <stronghuge>Institute of Artificial Intelligence and Robotics(IAIR), &nbsp; Xi'an Jiaotong University</stronghuge><br />
          <huge><em>M.S. Dissertation Project & Research Associate</em></huge> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Sep. 2020 - Present <br />
          Advisors: &nbsp; <a href="https://personal.ntu.edu.sg/eyptan/index.html">Yaochen Li</a>,
          <a href="https://personal.ntu.edu.sg/eackot/index.html">Yuehu Liu</a>
          
          <li> Lidar-based 3D Object Detection in Road Scenes. <br/>
          <li> Point Cloud Registration Based on Transformer.<br/>
          <li> Point Cloud Semantic Segmentation. <br/>
          </p>
        </td>
      </tr>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="10%">
            <img src='image2/ascend.png' width="100">
            </a>
          </td>

          <td width="80%" valign="middle">
          <p  style="line-height: 1.3em;">
          <stronghuge>Ascend Ecological Development Department,, &nbsp; Huawei</stronghuge><br />
          <huge><em>Research  Assistant</em></huge> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Mar. 2022 - Jun. 2022 <br />
          Advisor: <a href="http://www.jie-chen.com">Prof. Jie Chen</a>
          <li> Transplanted the deep learning model to Huawei’s Ascend AI processor for deployment. <br/>
          <li> Completed the compatibility and performance verification of both systems.<br/>
		  <li> Achieved the required accuracy and performance on the Ascend AI processor about several DL models.<br/>
          </p>
        </td>
      </tr>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="10%">
            <img src='image2/boyun.png' width="100">
            </a>
          </td>

          <td width="80%" valign="middle">
          <p  style="line-height: 1.3em;">
          <stronghuge>Boyun Vision (Beijing) Technology</stronghuge><br />
          <huge><em>Research  Assistant</em></huge> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Feb. 2021 - Jun. 2021 <br />
          
          <li> Building a classification detector for photos. <br/>
          <li> Building an anomaly detector for road guardrail photos. <br/>
          <li> Embed the detector into the app.
          </p>
        </td>
      </tr>

      


      
  


<p></p><p></p><p></p><p></p><p></p>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Publication <!--<a href="https://scholar.google.com/citations?user=LGM10RQAAAAJ&hl=en&oi=ao" style="font-size:22px;">[Google Scholar]</a></heading>-->
        </td>
      </tr>
      </table>


    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='image2/tadp.png'  width="200">
      </td>
      <td valign="top" width="75%">
	 <strong>TADP: Task-Aware Deformable Prediction for Single-Stage 3D Object Detection</strong><br>
	 <strong>Su Wang</strong>, Yaochen Li, Min Yang, Jiahao Nie, Rui Huang, Yuehu Liu.  &nbsp;(First Student Author)<br>  
        <em>IEEE International Conference on Information Communication and Signal Processing (ICRA 2023), <strong>CCF-B  CORE-B</strong>
          <br>
        <em>Area: Point Cloud Perception, Point Cloud Object Detection</em> <br>
        <p></p>
		<p>proposes a new point cloud single-stage detector TADP: Task-Aware Deformable Prediction 
		for Single-Stage 3D Object Detection. We propose TFRA module to extract 3D features with multiple scales. 
		MSFA module is adopted to fuse features in the scale-aware method. A plug-and-play task-aware deformation head (TADH)
		which is to reduce the misalignment of features in all tasks.
		</p>
      </td>
    </tr>
   </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='image2/RITNet.png'  width="200">
      </td>
      <td valign="top" width="75%">
	 <strong>RITNet: A Rotation Invariant Transformer based Network for Point Cloud Registration</strong><br>
	 Min Yang, Yaochen Li, <strong>Su Wang</strong>, Shaohan Yang, Hujun Liu.  &nbsp;(Second Student Author)<br>  
        <em>Accepted by IEEE International Conference on Tools with Artificial Intelligence (ICTAI 2022) <strong>CCF-C CORE-B</strong>
         <br>
        <em>Area: Action Recognition, Infrared Video</em> <br>
        <p></p>
		<p>We believe that enhancing point cloud boundary features can be further enhanced by rotation information. 
		We propose a rotation invariant representation to replace common 3D Cartesian coordinates . 
		Enhanced generalization to arbitrary orientations using a rotation-invariant Transformer for point cloud registration. 
		The insensitivity to data arrangement and quantity in Transformer technology is exploited to capture global structural 
		knowledge within local parts to perceive each point cloud.</p>
      </td>
    </tr>
   </table>
   
   
       <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='image2/multi-level.png'  width="200">
      </td>
      <td valign="top" width="75%">
	 <strong>Multi-level Object Detection by Multi-Sensor Perception of Traffic Scenes</strong><br>
	 Sheng Yuan, Qi Zhang, Li Zhu, <strong>Su Wang</strong>, Yujie Zang, Xi Zhao &nbsp;(Second Student Author)<br>
        <em>Accepted by SCI Neurocomputing <strong>JCR Q2</strong>
        <br>
        <em>Area: Action Recognition, Infrared Video</em> <br>
        <p></p>
		<p>we propose a novel framework for multi-level object detection by mutli-sensor perception from road scenes. Firstly, an improved 2D object detection method based on RetinaNet is 
		designed by the optimization of the sub-network of ResNet. The coordinate attention mechanism and bidirectional feature fusion mechanism are incorporated. Finally, we 
		propose a 3D object detection method based on an improved PointNet network. The point cloud data are projected into a frustum according to the 2D detection result, then 
		the frustum is segmented according to the linearly increased steps.</p>
      </td>
    </tr>
   </table>
   
   
   
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='image2/reforced_second.png'  width="200">
      </td>
      <td valign="top" width="75%">
	 <strong>Reinforced SECOND: Attentional 3D Object Detection with Residual Sparse Convolution</strong><br>
	 Qiao Li, Yaochen Li, Wenneng Tang, <strong>Su Wang</strong>, Xuehan Hou, Yuehu Liu  &nbsp;(Third Student Author)<br>
        <em>IEEE International Conference on Robotics and Automation (ICRA 2023) <strong>CCF-B  CORE-B</strong>
        <br>
        <em>Area: Action Recognition, Infrared Video</em> <br>
        <p></p>
		<p>we propose a 3D object detection method using SECOND as the baseline, namely Reinforced SECOND. 
		A robust voxel encoder network is firstly introduced that extracts voxelwise features. At the same time, the stacked triple 
		attention mechanism is developed to enhance crucial features of the voxels. The residual 3D sparse convolution (ResSpConv3D)
		unit is then designed to replace the normal 3D sparse convolution, which improves the feature extraction ability of the sparse 
		convolution layer while maintaining the original information. Furthermore, the proposed attentional feature fusion (AFF) module 
		is incorporated into the region proposal network, which adaptively fuses low-level spatial features and high-level semantic features. </p>
      </td>
    </tr>
   </table>
   

   
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="15%">
        <img src='image2/frustum.png'  width="200">
      </td>
      <td valign="top" width="75%">
	 <strong>Frustum PointNet for 3D Object Detection from Traffic Scenes</strong><br>
	 Yaochen Li, Liangyu Zuo, Yuehu Liu, Wenneng Tang,<strong>Su Wang</strong>, Weili Guan &nbsp;(Third Student Author)<br>
        <em>ACM Transactions on Multimedia Computing Communications and Applications
        <br>
        <em>Area: Multimodal Fusion, 3D Object Detection, </em> <br>
        <p></p>
		<p>We propose a novel 3D ConvNet with a deep architecture to realize action recognition in IR videos. 
      Besides, a residual fully connected module is introduced after the ConvNet backbone to improve the performance. 
      Furthermore, we employe a transfer learning strategy, i.e., the proposed method is pretrained on a large-scale visible spectrum dataset 
      and then ﬁnetuned with false-color version of IR images to generalize well in the action recognition task.</p>
      </td>
    </tr>
   </table>

<p></p><p></p><p></p><p></p><p></p>
   <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr>
      <td width="100%" valign="middle">
        <heading>Other Project</heading>
      </td>
    </tr>
    </table>
 

	
	<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="15%">
          <img src='image2/benke2.png' width="200">
          </a>
        </td>
 
        <td width="80%" valign="middle">
        <p>
        <stronghuge>Object Detection Algorithm, &nbsp; <br />
          Bachelor Diploma thesis (Design), &nbsp; Xi'an Jiaotong University</stronghuge><br />
        <huge><em>Grade: A-</em></huge> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Feb. 2020 - Jun. 2020 <br />
        <li> We improve the F-PointNet algorithm to detect 3D object. <br/>
		
        </p>
      </td>
    </tr>
	
 
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="15%">
          <img src='image2/benke.png' width="200">
          </a>
        </td>
 
        <td width="80%" valign="middle">
        <p>
        <stronghuge>Road Scene Simulation System, &nbsp; <br />
          Bachelor Diploma thesis (Design), &nbsp; Xi'an Jiaotong University</stronghuge><br />
        <huge><em>Grade: A-</em></huge> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Feb. 2020 - Jun. 2020 <br />
        <li> Build a model of the road junction using Unity. <br/>
        <li> Design car models and create movement algorithms <br/>
        </p>
      </td>
    </tr>
	

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="15%">
          <img src='image2/glodon.jpg' width="200">
          </a>
        </td>
 
        <td width="80%" valign="middle">
        <p>
        <stronghuge>Glodon limited liability company&nbsp; NWPU</stronghuge><br />
        <huge><em>Summer Internship</em></huge> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &bull; Jul. 2019 - Aug. 2019 <br />
        <li> Use spring boot to make web pages. <br/>

        </p>
      </td>
    </tr>




    <p></p><p></p><p></p><p></p><p></p>
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
          <tr>
            <td width="100%" valign="middle">
              <heading>Activity</heading>
              <div style="line-height:25px">
              <p>
          <li> <stronghuge>Monitor, Xi'an Jiaotong University, XJTU</stronghuge>&nbsp; 2020 - 2023<br/>
		  <li> <stronghuge>Academic assistant, SOFT300327 Data Structure Ⅲ01, Xi'an Jiaotong University, XJTU</stronghuge>&nbsp; 2021 - 2022<br/>
		  <li> <stronghuge>Academic assistant, SOFT610111 Principles and Technology of Artificial Intelligence, , Xi'an Jiaotong University, XJTU</stronghuge> &nbsp; 2021 - 2022<br/>
          <li> <stronghuge>Vice Chairman, Student Union of Suzhou Research Institute, Xi'an Jiaotong University, XJTU</stronghuge>&nbsp; 2020 - 2021<br/>
          
		  <li> <stronghuge>Vice Chairman, Community Management Committee, Xi'an Jiaotong University, XJTU</stronghuge>&nbsp; 2018 - 2019<br/>
          
		      </p>
              </div>
            </td>
          </tr>
    </table>







<p></p><p></p><p></p><p></p><p></p>
<table style="width:25%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>
  <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=OnTintSFonO7-K8tIUMxW0S9HCuQMwuQfZ9IXD_tToI&cl=ffffff&w=a"></script>
</tbody>
</table>

<p></p><p></p><p></p><p></p><p></p>
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
  <tbody>

      <tr>
          <td style="padding:0px">
              <p style="text-align:left;font-size:small;"> This homepage was last updated: <span id="demo"></span>.</p>
              <script>document.getElementById("demo").innerHTML = document.lastModified;</script>
          </td>
          <td>
              <p style="text-align:right;font-size:small;">
                  This awesome website template is borrowed from <a href="https://jonbarron.info/" target="_blank">Jon Barron</a>.
              </p>
          </td>
      </tr>
  </tbody>
</table>
   

</body>
</html>
